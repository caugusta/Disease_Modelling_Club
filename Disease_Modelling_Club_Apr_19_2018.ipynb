{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for predicting the class of an epidemic curve#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll build a (small!) multilayer perceptron, train it, and use it to predict the class of a epidemic curve. To make this tutorial work, you'll need to download Python3 and install several packages (including numpy, tensorflow, pandas, and Keras). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available on my GitHub, [here](https://github.com/caugusta/Disease_Modelling_Club). You should download 2 files:\n",
    "\n",
    "- train_data.csv (~200 KB)\n",
    "- test_data.csv (~50 KB)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the dataset##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of simulated epidemic curves (counts of infectious individuals per time unit). An SIR model was used, and three types of epidemics were generated:\n",
    "\n",
    "- one that travels relatively slowly through the population (class 0, yellow in the image below)\n",
    "- one that travels very quickly through the population (class 1, grey)\n",
    "- one that travels not as quickly through the population (class 2, pink)\n",
    "\n",
    "For those of you who are interested, the population of interest was simulated locations of 413 swine farms in Sioux County, Iowa, based on the [FLAPS online farm location simulator](http://flaps.biology.colostate.edu/) from Colorado State University's Dr. Chris Burdett. At time of writing this tutorial, **FLAPS is down**, but I'm hoping it'll be up and running again soon. This is part of the dataset that was used for this paper [1].\n",
    "\n",
    "These epidemics will look somewhat strange, because they've been padded with 0s so that each epidemic has the same length (this is necessary for input to a multilayer perceptron, more on that later).\n",
    "\n",
    "An epidemic curve from class 0 looks like this:\n",
    "\n",
    "4 19 17 28 30 40 51 46 31 40 29 24 11 10 9 1 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "\n",
    "This means that 4 farms were initially infected with the disease (day 1 had 4 infectious farms); day 2 had 19 infectious farms, etc.\n",
    "\n",
    "The '0' on the end of this particular epidemic means that this epidemic curve was generated from class 0 (this is a fast epidemic). In this epidemic, 4+19+...+1 = 403 farms were infected. This epidemic lasted 19 days.\n",
    "\n",
    "An epidemic curve from class 1 looks like this:\n",
    "\n",
    "4 33 107 194 71 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    "\n",
    "Note there are many more infectious farms at the beginning. 412 farms got infected in 6 days - that's a wildfire-fast epidemic! And the '1' at the end denotes that this epidemic belongs to class 1.\n",
    "\n",
    "An epidemic curve from class 2 looks like this:\n",
    "\n",
    "4 20 40 79 104 86 49 21 6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
    "\n",
    "This epidemic lasted 11 days.\n",
    "\n",
    "If you were to graph the epidemic curves (number of infectious farms vs index of day), it would look like this:\n",
    "\n",
    "<img src=\"ThreeEpidemics_DMC-1.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "These three classes of epidemic look very different from one another, so we would expect a classifer to perform very well. This is an extreme example, to show how the classifier works, but in reality there could be some epidemics from the yellow group that look more like epidemics from the pink group. The power of these types of models is in how they learn to distinguish types of epidemic curves _even when those epidemic curves look very similar_. For this tutorial, the goal is to understand more about how a multilayer perceptron works, so that's another topic for another day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classifer: a multilayer perceptron (MLP)##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's get started with some code. In Python, the first thing we do is import the various modules we'll be using. If you run the code below, there shouldn't be any output, except perhaps 'Using TensorFlow backend'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import string\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to read in the data we're planning to use. Note you will need to modify the path (the './Desktop/DMC/New_Presentation/Disease_Modelling_Club' part) below to the location in which you saved train_data.csv and test_data.csv. We'll load the data, and manipulate it into a useable form.\n",
    "\n",
    "Keras, the API we'll be using to build our MLP, requires numpy arrays as input. So we have to convert each of our epidemic curves to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "\n",
    "with open('./Desktop/DMC/New_Presentation/Disease_Modelling_Club/train_data.csv', 'r') as f:\n",
    "    train_data = f.readlines()\n",
    "    \n",
    "with open('./Desktop/DMC/New_Presentation/Disease_Modelling_Club/test_data.csv', 'r') as f:\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "#Right now, train_data is a list of strings.    \n",
    "#We can visualize the first line of the training data to make sure things read in properly:\n",
    "\n",
    "#train_data[0]\n",
    "#'4,19,17,28,30,40,51,46,31,40,29,24,11,10,9,1,3,9,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'\n",
    "\n",
    "\n",
    "train_no_newline = [s.rstrip() for s in train_data] #remove \\n from the end of each line\n",
    "train_lists = [list(s) for s in train_no_newline]\n",
    "#translator = str.maketrans('', '', string.punctuation)\n",
    "#train_list=[list(s.translate(translator)) for s in train_no_newline]\n",
    "#train_no_newline = [s.translate(None, string.punctuation) for s in train_data]\n",
    "#train_array = np.asarray(train_list)\n",
    "\n",
    "#train_df = pd.DataFrame(train_data) #convert to a dataframe, similar to R.\n",
    "#train_df = train_df.replace(r'\\n',' ', regex=True) #remove \\n from the end of each line\n",
    "#train_df = train_df.apply(lambda x: x.as_matrix)\n",
    "\n",
    "#train_mat = train_df.as_matrix() #convert to a numpy array, similar to R's matrix class.\n",
    "\n",
    "##train_mat.shape #(2400, 1) - the shape of the array of training epidemic curves.\n",
    "\n",
    "##Now also fix the test set\n",
    "\n",
    "#test_df = pd.DataFrame(test_data)\n",
    "#test_df = test_df.replace(r'\\n',' ', regex=True)\n",
    "#test_df = test_df.as_matrix()\n",
    "\n",
    "##test_df.shape #(600, 1) - 600 epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['4', '1', '9', '1', '7', '2', '8', '3', '0', '4', '0', '5', '1', '4', '6', '3', '1', '4', '0', '2', '9', '2', '4', '1', '1', '1', '0', '9', '1', '3', '9', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']),\n",
       "       list(['4', '2', '5', '2', '0', '3', '6', '4', '1', '3', '5', '4', '9', '3', '7', '3', '9', '4', '2', '3', '0', '1', '3', '1', '5', '6', '5', '4', '2', '2', '3', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']),\n",
       "       list(['4', '1', '5', '2', '7', '3', '9', '4', '4', '3', '7', '4', '2', '3', '5', '4', '2', '2', '9', '2', '3', '1', '8', '1', '3', '1', '0', '5', '7', '6', '6', '2', '3', '2', '0', '2', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']),\n",
       "       ...,\n",
       "       list(['4', '1', '2', '3', '1', '6', '8', '9', '8', '1', '1', '1', '5', '6', '1', '9', '9', '3', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2']),\n",
       "       list(['4', '1', '2', '2', '7', '5', '5', '9', '9', '1', '1', '0', '6', '9', '2', '6', '7', '2', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2']),\n",
       "       list(['4', '1', '4', '3', '8', '9', '1', '1', '2', '4', '8', '4', '3', '9', '1', '4', '3', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df[0] #a pandas.core.series.Series\n",
    "#train_df[0][0] # a str object\n",
    "#train_no_newline[0]\n",
    "#type(train_lists)\n",
    "#type(train_lists[0])\n",
    "#train_lists[0]\n",
    "train_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is common in machine learning, we should normalize the input before we feed it in to our model. That means we'll subtract the mean of the training data and divide by the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete code for this entire tutorial, all together, is available on my GitHub(here) for anyone who would like to play with it! If you use these data in a presentation or publication, please cite me.\n",
    "\n",
    "[1] Augusta, C., R. Deardon and G. W. Taylor. Deep learning for classifying epidemic curves. [Under review] Spatial and Spatio-Temporal Epidemiology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
