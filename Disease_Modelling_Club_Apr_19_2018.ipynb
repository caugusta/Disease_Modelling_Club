{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for predicting the class of an epidemic curve#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll build a (small!) multilayer perceptron, train it, and use it to predict the class of a epidemic curve. To make this tutorial work, you'll need to download Python3 and install several packages (including numpy, tensorflow, pandas, and Keras). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available on my GitHub, [here](https://github.com/caugusta/Disease_Modelling_Club). You should download 2 files:\n",
    "\n",
    "- train_data.csv (~200 KB)\n",
    "- test_data.csv (~50 KB)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the dataset##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of simulated epidemic curves (counts of infectious individuals per time unit). An SIR model was used, and three types of epidemics were generated:\n",
    "\n",
    "- one that travels relatively slowly through the population (class 0, yellow in the image below)\n",
    "- one that travels very quickly through the population (class 1, grey)\n",
    "- one that travels not as quickly through the population (class 2, pink)\n",
    "\n",
    "For those of you who are interested, the population of interest was simulated locations of 413 swine farms in Sioux County, Iowa, based on the [FLAPS online farm location simulator](http://flaps.biology.colostate.edu/) from Colorado State University's Dr. Chris Burdett. At time of writing this tutorial, **FLAPS is down**, but I'm hoping it'll be up and running again soon. This is part of the dataset that was used for this paper [1].\n",
    "\n",
    "These epidemics will look somewhat strange, because they've been padded with 0s so that each epidemic has the same length (this is necessary for input to a multilayer perceptron, more on that later).\n",
    "\n",
    "An epidemic curve from class 0 looks like this:\n",
    "\n",
    "4 19 17 28 30 40 51 46 31 40 29 24 11 10 9 1 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "\n",
    "This means that 4 farms were initially infected with the disease (day 1 had 4 infectious farms); day 2 had 19 infectious farms, etc.\n",
    "\n",
    "The '0' on the end of this particular epidemic means that this epidemic curve was generated from class 0 (this is a fast epidemic). In this epidemic, 4+19+...+1 = 403 farms were infected. This epidemic lasted 19 days.\n",
    "\n",
    "An epidemic curve from class 1 looks like this:\n",
    "\n",
    "4 33 107 194 71 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    "\n",
    "Note there are many more infectious farms at the beginning. 412 farms got infected in 6 days - that's a wildfire-fast epidemic! And the '1' at the end denotes that this epidemic belongs to class 1.\n",
    "\n",
    "An epidemic curve from class 2 looks like this:\n",
    "\n",
    "4 20 40 79 104 86 49 21 6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
    "\n",
    "This epidemic lasted 11 days.\n",
    "\n",
    "If you were to graph the epidemic curves (number of infectious farms vs index of day), it would look like this:\n",
    "\n",
    "[IMAGE](https://github.com/caugusta/Disease_Modelling_Club/blob/master/ThreeEpidemics_DMC-1.png)\n",
    "\n",
    "These three classes of epidemic look very different from one another, so we would expect a classifer to perform very well. This is an extreme example, to show how the classifier works, but in reality there could be some epidemics from the yellow group that look more like epidemics from the pink group. The power of these types of models is in how they learn to distinguish types of epidemic curves _even when those epidemic curves look very similar_. For this tutorial, the goal is to understand more about how a multilayer perceptron works, so that's another topic for another day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multilayer perceptron (MLP) for classifying epidemic curves##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's get started with some code. In Python, the first thing we do is import the various modules we'll be using. If you run the code below, there shouldn't be any output, except perhaps 'Using TensorFlow backend'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to read in the data we're planning to use. We'll load the data, and manipulate it into a useable form.\n",
    "\n",
    "Keras, the API we'll be using to build our MLP, requires numpy arrays as input. So we have to convert each of our epidemic curves to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anything preceded by # in Python is a comment.\n",
    "\n",
    "seed = 2018\n",
    "np.random.seed(seed) #this is to make sure all our results are reproducible.\n",
    "\n",
    "#Reading in the data\n",
    "\n",
    "#If you saved the files elsewhere, include the full path in the ' ' below. \n",
    "# For example, if you saved train_data.csv in /my/dir, \n",
    "# which is a sub-directory of the current directory, then the next line should read:\n",
    "# with open('./my/dir/train_data.csv', 'r') as f:\n",
    "\n",
    "with open('train_data.csv', 'r') as f: \n",
    "    train_data = f.readlines()\n",
    "    \n",
    "with open('test_data.csv', 'r') as f:\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "#Right now, train_data is a list of strings.    \n",
    "#We can visualize the first line of the training data to make sure things read in properly:\n",
    "\n",
    "#train_data[0]\n",
    "#'4 19 17 28 30 40 51 46 31 40 29 24 11 10 9 1 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \"0\"\\n'\n",
    "\n",
    "train_no_newline = [s.rstrip() for s in train_data] #remove \\n from the end of each line\n",
    "\n",
    "#train_no_newline[0]\n",
    "#'4 19 17 28 30 40 51 46 31 40 29 24 11 10 9 1 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \"0\"'\n",
    "\n",
    "train_no_quotes = [s.replace('\"', '') for s in train_no_newline] # remove \"\" from 0 at end.\n",
    "\n",
    "#train_no_quotes[0]\n",
    "#'4 19 17 28 30 40 51 46 31 40 29 24 11 10 9 1 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n",
    "\n",
    "#Convert the string values to integers\n",
    "train_as_list = list()\n",
    "for i in range(len(train_no_quotes)):\n",
    "    for j in range(len(train_no_quotes[i].split())):\n",
    "        train_as_list.append(int(train_no_quotes[i].split()[j]))\n",
    "\n",
    "#Convert the list to an array\n",
    "\n",
    "train_array = np.asarray(train_as_list)\n",
    "\n",
    "train_array = train_array.reshape((2400, 34))\n",
    "\n",
    "#train_array[0,:] NOTE how indexing an array is different! \n",
    "#There are 2 dimensions. We want row 0 and all columns printed out.\n",
    "\n",
    "#array([ 4, 19, 17, 28, 30, 40, 51, 46, 31, 40, 29, 24, 11, 10,  9,  1,  3,\n",
    "#        9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
    "\n",
    "#Now do the same for the test set.\n",
    "\n",
    "test_no_newline = [s.rstrip() for s in test_data]\n",
    "test_no_quotes = [s.replace('\"', '') for s in test_no_newline]\n",
    "\n",
    "test_as_list = list()\n",
    "for i in range(len(test_no_quotes)):\n",
    "    for j in range(len(test_no_quotes[i].split())):\n",
    "        test_as_list.append(int(test_no_quotes[i].split()[j]))\n",
    "        \n",
    "test_array = np.asarray(test_as_list)\n",
    "test_array = test_array.reshape((600, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, we have some integers that are true integers (counts of infectious farms each day), and we have some integers that are just there to denote that the epidemic belongs to class 0, class 1, or class 2. Those are stored in the last column of the array.\n",
    "\n",
    "We want to make sure Keras understands that 0, 1, 2 at the end of the array just means a class label, and is not part of the counts of infectious farms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_labels = train_array[:, :-1] #means \"all rows and all columns except last column\"\n",
    "train_labels = train_array[:,-1] #means \"all rows and only last column\"\n",
    "\n",
    "#With thanks to [2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_labels)\n",
    "Y_train = encoder.transform(train_labels)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(Y_train)\n",
    "\n",
    "test_no_labels = test_array[:,:-1]\n",
    "test_labels = test_array[:,-1]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(test_labels)\n",
    "Y_test = encoder.transform(test_labels)\n",
    "dummy_y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "#Now, when I was making the datasets, I should have ensured \n",
    "#the training set had the same number of columns as the test set.\n",
    "#Fixing that now....\n",
    "N = test_no_labels.shape[0] #number of rows\n",
    "M = test_no_labels.shape[1] #number of columns\n",
    "test_no_labels_2 = np.zeros((N, M+1)) #create a matrix of 0s with N rows and M+1 columns\n",
    "test_no_labels_2[:, :-1] = test_no_labels #insert test epidemics up to last column\n",
    "\n",
    "#test_no_labels.shape #(600, 32)\n",
    "#test_no_labels_2.shape #(600, 33)\n",
    "#train_no_labels.shape #(2400, 33) \n",
    "\n",
    "test_no_labels = test_no_labels_2 #reassigning the variable name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is common in machine learning, we should normalize the input before we feed it in to our model. That means we'll subtract the mean of the training data and divide by the standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use = (train_no_labels - np.mean(train_no_labels))/np.std(train_no_labels)\n",
    "\n",
    "#train_use[0,:]\n",
    "#array([-0.28472025,  0.2416698 ,  0.17148446,  0.55750384,  0.62768918,...])\n",
    "\n",
    "test_use = (test_no_labels - np.mean(test_no_labels))/(np.std(test_no_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our MLP, we will need an input layer, two hidden layers, and an output layer. This will be a very small network, because we want to be able to train this locally. If you're looking this up later, we're using Keras's functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "hidden_1 (Dense)             (None, 10)                340       \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 483\n",
      "Trainable params: 483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Our MLP will have four layers: an input layer, two hidden layers, and an output layer\n",
    "#the input layer has size 33 because that's the length of our epidemic curves\n",
    "#it will pass these epidemics to the first hidden layer, hidden_1\n",
    "\n",
    "#hidden_1 with 10 hidden units will compute sigma(W_1*X + b_1) and pass it to the next layer\n",
    "#hidden_2 with 8 hidden units will compute sigma(W_2*hidden_1 + b_2) and pass it to the next layer\n",
    "\n",
    "#the output layer with 3 output units will compute \n",
    "#the probability that the epidemic curve belongs to each class\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(33,), name='input_layer') #take in an unspecified number of epidemic curves, each of length 33\n",
    "hidden_1 = Dense(10, activation=\"sigmoid\", name=\"hidden_1\")(input_layer) # a hidden layer with 10 units that takes in the input\n",
    "hidden_2 = Dense(10, activation=\"sigmoid\", name=\"hidden_2\")(hidden_1) #a hidden layer with 5 units that takes in compute values from the previous hidden layer\n",
    "output_layer = Dense(3, activation=\"softmax\", name=\"output_layer\")(hidden_2) #the output layer\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=output_layer)\n",
    "\n",
    "#We can see the shape of each layer, and the number of parameters in the model,\n",
    "#using summary()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built the model, we have to find optimal values for each of the 209 parameters. The process of finding the optimal values is called model training.\n",
    "\n",
    "When we train a model, we want the model to learn abstract features that identify an epidemic as belonging to a class. That means we need to shuffle the dataset - that is, we need to randomize the order, so our model doesn't learn that the first 100 epidemic curves all belong to the same class. We'll do this in model.fit() below. It's true by default but we'll state it explicitly anyway.\n",
    "\n",
    "Also, usefully, we can provide the test data at the same time. The model will see only the training data while we're trying to update parameter values using stochastic gradient descent (SGD), but after each epoch, it'll see the validation data (but these will not inform parameter updates. This is just a way of seeing how the model is doing so far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.0833 - acc: 0.4279 - val_loss: 1.0458 - val_acc: 0.6667\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.0327 - acc: 0.7250 - val_loss: 1.0205 - val_acc: 0.9883\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.0093 - acc: 0.9942 - val_loss: 0.9975 - val_acc: 0.9950\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.9857 - acc: 0.9892 - val_loss: 0.9726 - val_acc: 0.9983\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.9589 - acc: 0.9929 - val_loss: 0.9444 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.9284 - acc: 0.9987 - val_loss: 0.9116 - val_acc: 0.9967\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.8935 - acc: 0.9958 - val_loss: 0.8743 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.8538 - acc: 0.9962 - val_loss: 0.8326 - val_acc: 0.9967\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.8100 - acc: 0.9992 - val_loss: 0.7873 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.7634 - acc: 0.9958 - val_loss: 0.7394 - val_acc: 0.9983\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10 #this is the number of times we'll iterate over the training dataset.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#We'll feed 20 epidemic curves in to the model at a time.\n",
    "model_training = model.fit(train_use, dummy_y, validation_data = (test_use, dummy_y_test), epochs=num_epochs, batch_size=20, shuffle=True, verbose=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a working model of what each type of epidemic curve looks like, with an accuracy of greater than 99%, let's visualize the results. This code is taken directly from [3]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a308fb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(model_training.history['acc'])\n",
    "plt.plot(model_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results will not match what's in the paper, because it's a gross oversimplification of the problem. We only have 3 classes here, whereas in the paper we had up to 16 classes. We also only tried an MLP here, with a very simple formulation, and didn't explore any hyperparameter selection. A hyperparameter has to do with model setup. It can be anything from the number of hidden units per layer, to the way we initialize the hidden units, to the optimizer we choose, etc. Here we focused on epidemics that were very easy to classify, to make sure model training would run smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to get more info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete code for this entire tutorial, all together, is available on my GitHub [here](https://github.com/caugusta/Disease_Modelling_Club/blob/master/code_from_Disease_Modelling_Club_Apr_19_2018.py) for anyone who would like to play with it! If you use these data in a presentation or publication, please cite my advisors and me (citation [1] below).\n",
    "\n",
    "If you're looking for more resources, I highly recommend machinelearningmastery (citations [2] and [3] below). You can also read the paper [Deep Learning: An Introduction for Applied Mathematicians](https://arxiv.org/abs/1801.05894), which provides a really good overview of what's going on in deep neural networks.\n",
    "\n",
    "[1] Augusta, C., R. Deardon and G. W. Taylor. Deep learning for classifying epidemic curves. [Under review] Spatial and Spatio-Temporal Epidemiology. \n",
    "\n",
    "[2] https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "\n",
    "[3] https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
